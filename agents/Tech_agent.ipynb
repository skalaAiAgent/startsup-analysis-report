{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 스타트업 기술 평가 에이전트 (웹 크롤링 + PDF 분석)\n",
    "## EnsembleRetriever (BM25 + Semantic) with ChromaDB\n",
    "\n",
    "이 노트북은 Langgraph를 사용하여 AI 스타트업의 기술력을 평가하는 에이전트를 구현합니다.\n",
    "- Embedding: Ollama (nomic-embed-text)\n",
    "- LLM: GPT-4o-mini\n",
    "- VectorDB: ChromaDB\n",
    "- Retrieval: **EnsembleRetriever** (BM25Retriever + SemanticRetriever)\n",
    "- Data Sources: Tavily Web Search + PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 설치\n",
    "# !pip install langchain langgraph langchain-openai langchain-community chromadb rank-bm25 ollama\n",
    "# !pip install beautifulsoup4 requests pypdf unstructured\n",
    "# !pip install langchain-text-splitters\n",
    "# !pip install tavily-python python-dotenv  # Tavily 검색 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Annotated\n",
    "from operator import add\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKAX\\AppData\\Local\\Temp\\ipykernel_16932\\2150461561.py:3: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")  # 현재 설치된 임베딩 모델\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)  # 점수 다양성을 위해 temperature 증가\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")  # 현재 설치된 임베딩 모델\n",
    "\n",
    "# PDF 데이터 경로\n",
    "PDF_DATA_PATH = Path(r\"C:\\workspace\\demo-app\\skala_gai\\data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"에이전트의 상태를 정의하는 클래스\"\"\"\n",
    "    startup_names: List[str]  # 평가할 스타트업 이름 리스트 (최대 5개)\n",
    "    current_startup: str  # 현재 평가 중인 스타트업\n",
    "    web_data: str  # 웹 크롤링 데이터\n",
    "    retrieved_docs: List[Document]  # 검색된 문서들\n",
    "    tech_evaluations: List[Dict]  # 기술 평가 결과들 - Annotated 제거하고 일반 List로 변경\n",
    "    processing_index: int  # 현재 처리 중인 인덱스\n",
    "    vectorstore_ready: bool  # VectorStore 준비 완료 여부\n",
    "    #\n",
    "\n",
    "    #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PDF 문서 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_documents(pdf_dir: Path) -> List[Document]:\n",
    "    \"\"\"PDF 문서들을 로드하고 청킹\"\"\"\n",
    "    all_documents = []\n",
    "    \n",
    "    # PDF 파일들 찾기\n",
    "    pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "    print(f\"발견된 PDF 파일: {len(pdf_files)}개\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            print(f\"로딩 중: {pdf_file.name}\")\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # 메타데이터 추가\n",
    "            for doc in documents:\n",
    "                doc.metadata[\"source_file\"] = pdf_file.name\n",
    "                doc.metadata[\"source_type\"] = \"pdf\"\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "        except Exception as e:\n",
    "            print(f\"PDF 로드 실패 ({pdf_file.name}): {e}\")\n",
    "    \n",
    "    # 텍스트 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    split_documents = text_splitter.split_documents(all_documents)\n",
    "    print(f\"총 {len(split_documents)}개의 청크 생성\")\n",
    "    \n",
    "    return split_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 웹 크롤링 함수 (Tavily + Fallback)\n",
    "\n",
    "### 검색 전략:\n",
    "1. **1순위: Tavily API** - LLM 최적화된 검색 (안정적, 고품질)\n",
    "2. **2순위: 전통적 크롤링** - Tavily 실패 시 대체 (네이버, DuckDuckGo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_startup_info(startup_name: str, max_results: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    스타트업 정보를 웹에서 크롤링 (Tavily)\n",
    "    \n",
    "    Args:\n",
    "        startup_name: 스타트업 이름\n",
    "        max_results: 수집할 최대 결과 수\n",
    "    \n",
    "    Returns:\n",
    "        크롤링된 텍스트 데이터\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"웹 검색 시작: {startup_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1순위: Tavily 시도\n",
    "    try:\n",
    "        result = crawl_with_tavily(startup_name, max_results)\n",
    "        if result and len(result) > 100:  # 유의미한 결과\n",
    "            print(f\"✓ Tavily 검색 성공\\n\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"✗ Tavily 결과 부족, 대체 방법 시도...\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Tavily 오류: {str(e)[:50]}\")\n",
    "\n",
    "\n",
    "def crawl_with_tavily(startup_name: str, max_results: int) -> str:\n",
    "    \"\"\"\n",
    "    Tavily API를 사용한 검색 (LLM 최적화)\n",
    "    \n",
    "    Args:\n",
    "        startup_name: 스타트업 이름\n",
    "        max_results: 수집할 최대 결과 수\n",
    "    \n",
    "    Returns:\n",
    "        검색된 텍스트 데이터\n",
    "    \"\"\"\n",
    "    from tavily import TavilyClient\n",
    "    \n",
    "    # API 키 확인\n",
    "    api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"TAVILY_API_KEY가 설정되지 않았습니다.\")\n",
    "    \n",
    "    print(f\"  [Tavily] 검색 중...\")\n",
    "    \n",
    "    # 클라이언트 초기화\n",
    "    client = TavilyClient(api_key=api_key)\n",
    "    \n",
    "    # 검색 쿼리 구성\n",
    "    queries = [\n",
    "        f\"{startup_name} 스타트업 기술 혁신\",\n",
    "        f\"{startup_name} AI 투자 비즈니스\"\n",
    "    ]\n",
    "    \n",
    "    collected_text = []\n",
    "    \n",
    "    for idx, query in enumerate(queries, 1):\n",
    "        try:\n",
    "            print(f\"    쿼리 {idx}: {query}\")\n",
    "            \n",
    "            response = client.search(\n",
    "                query=query,\n",
    "                search_depth=\"basic\",  # \"basic\" 또는 \"advanced\"\n",
    "                max_results=max_results,\n",
    "                include_answer=True,  # AI 생성 요약 포함\n",
    "                include_raw_content=False,\n",
    "                include_domains=None,  # 모든 도메인 허용\n",
    "                days=365  # 최근 1년 데이터\n",
    "            )\n",
    "            \n",
    "            # AI 생성 요약 (매우 중요!)\n",
    "            if response.get('answer'):\n",
    "                collected_text.append(\n",
    "                    f\"[AI 요약] {response['answer']}\"\n",
    "                )\n",
    "                print(f\"      ✓ AI 요약 수집\")\n",
    "            \n",
    "            # 검색 결과\n",
    "            results = response.get('results', [])\n",
    "            print(f\"      ✓ {len(results)}개 출처 발견\")\n",
    "            \n",
    "            for result in results:\n",
    "                title = result.get('title', '')\n",
    "                content = result.get('content', '')\n",
    "                url = result.get('url', '')\n",
    "                score = result.get('score', 0)\n",
    "                \n",
    "                if content and len(content) > 50:\n",
    "                    collected_text.append(\n",
    "                        f\"[출처: {url}]\\n\"\n",
    "                        f\"제목: {title}\\n\"\n",
    "                        f\"내용: {content}\\n\"\n",
    "                        f\"관련성: {score:.2f}\"\n",
    "                    )\n",
    "            \n",
    "            time.sleep(0.3)  # Rate limiting\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      ✗ 쿼리 실패: {str(e)[:50]}\")\n",
    "            continue\n",
    "    \n",
    "    if not collected_text:\n",
    "        raise ValueError(\"Tavily에서 유의미한 결과를 찾지 못했습니다.\")\n",
    "    \n",
    "    result_text = \"\\n\\n\".join(collected_text)\n",
    "    print(f\"    총 {len(collected_text)}개 항목 수집\")\n",
    "    \n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Retriever 구성 (BM25 + Semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnsembleRetriever는 VectorStore 초기화 시 함께 구성됩니다.\n"
     ]
    }
   ],
   "source": [
    "# EnsembleRetriever: BM25Retriever + Semantic Retriever를 결합\n",
    "# \n",
    "# BM25Retriever: 키워드 기반 검색 (전통적 정보 검색)\n",
    "# Semantic Retriever (VectorStore): 의미 기반 벡터 검색\n",
    "# \n",
    "# weights 파라미터로 각 retriever의 가중치 조절 가능\n",
    "# - [0.5, 0.5]: 동일한 가중치 (기본값)\n",
    "# - [0.7, 0.3]: BM25 중시\n",
    "# - [0.3, 0.7]: Semantic 중시\n",
    "\n",
    "print(\"EnsembleRetriever는 VectorStore 초기화 시 함께 구성됩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. VectorStore 초기화\n",
    "\n",
    "**설정:**\n",
    "- `FORCE_REBUILD = False`: 기존 ChromaDB를 재사용 (빠름)\n",
    "- `FORCE_REBUILD = True`: 강제로 재생성 (PDF 수정 시 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🆕 기존 VectorStore 없음 - 새로 생성\n",
      "============================================================\n",
      "임베딩 생성 중 (처음 실행 시 시간 소요)...\n",
      "\n",
      "PDF 문서 로드 중...\n",
      "발견된 PDF 파일: 3개\n",
      "로딩 중: 강소 스타트업 기술 트렌드 리포트.pdf\n",
      "로딩 중: 스타트업 생태계 트렌드 리포트.pdf\n",
      "로딩 중: 한국 AI 창업 인큐베이터 생태계 파노라마 분석.pdf\n",
      "총 158개의 청크 생성\n",
      "\n",
      "VectorStore 생성 중 (임베딩 생성 - 수 분 소요 가능)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ VectorStore 생성 완료!\n",
      "\n",
      "============================================================\n",
      "🔧 EnsembleRetriever 구성 중...\n",
      "============================================================\n",
      "✓ BM25Retriever 생성 완료 (k=5)\n",
      "✓ SemanticRetriever 생성 완료 (k=5)\n",
      "✓ EnsembleRetriever 생성 완료 (weights=[0.5, 0.5])\n",
      "\n",
      "============================================================\n",
      "✅ 초기화 완료\n",
      "============================================================\n",
      "PDF 문서 수: 158개\n",
      "컬렉션 이름: startup_tech_db\n",
      "저장 위치: ../rag/tech/chroma_db\n",
      "Retriever 구성: BM25 (50%) + Semantic (50%)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import shutil\n",
    "\n",
    "# ====== 설정 옵션 ======\n",
    "FORCE_REBUILD = False  # True로 설정하면 기존 DB 삭제하고 재생성\n",
    "# =======================\n",
    "\n",
    "CHROMA_PERSIST_DIR = \"../rag/tech/chroma_db\"\n",
    "CHROMA_COLLECTION_NAME = \"startup_tech_db\"\n",
    "\n",
    "# 강제 재생성 옵션이 활성화된 경우\n",
    "if FORCE_REBUILD and os.path.exists(CHROMA_PERSIST_DIR):\n",
    "    print(\"⚠️ FORCE_REBUILD=True: 기존 VectorStore를 삭제합니다...\")\n",
    "    shutil.rmtree(CHROMA_PERSIST_DIR)\n",
    "    print(\"✓ 삭제 완료\\n\")\n",
    "\n",
    "# 이미 ChromaDB가 존재하는지 확인\n",
    "if os.path.exists(CHROMA_PERSIST_DIR) and os.path.isdir(CHROMA_PERSIST_DIR):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📂 기존 VectorStore 발견!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"저장된 임베딩 데이터를 로드합니다 (임베딩 생성 생략)...\\n\")\n",
    "    \n",
    "    # 기존 ChromaDB 로드 (PDF 로드 및 임베딩 생성 생략)\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=CHROMA_COLLECTION_NAME,\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=CHROMA_PERSIST_DIR\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ VectorStore 로드 완료!\")\n",
    "    \n",
    "    # PDF 문서도 로드 (BM25용으로 필요)\n",
    "    print(\"\\nPDF 문서 로드 중 (BM25 인덱스용)...\")\n",
    "    pdf_documents = load_pdf_documents(PDF_DATA_PATH)\n",
    "    \n",
    "else:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🆕 기존 VectorStore 없음 - 새로 생성\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"임베딩 생성 중 (처음 실행 시 시간 소요)...\\n\")\n",
    "    \n",
    "    # PDF 문서 로드\n",
    "    print(\"PDF 문서 로드 중...\")\n",
    "    pdf_documents = load_pdf_documents(PDF_DATA_PATH)\n",
    "    \n",
    "    # ChromaDB 벡터스토어 생성\n",
    "    print(\"\\nVectorStore 생성 중 (임베딩 생성 - 수 분 소요 가능)...\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=pdf_documents,\n",
    "        embedding=embeddings,\n",
    "        collection_name=CHROMA_COLLECTION_NAME,\n",
    "        persist_directory=CHROMA_PERSIST_DIR\n",
    "    )\n",
    "    \n",
    "    print(\"✓ VectorStore 생성 완료!\")\n",
    "\n",
    "# ========== EnsembleRetriever 구성 ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔧 EnsembleRetriever 구성 중...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. BM25Retriever 생성 (키워드 기반)\n",
    "bm25_retriever = BM25Retriever.from_documents(pdf_documents)\n",
    "bm25_retriever.k = 5  # 상위 5개 문서 반환\n",
    "\n",
    "print(f\"✓ BM25Retriever 생성 완료 (k={bm25_retriever.k})\")\n",
    "\n",
    "# 2. Semantic Retriever 생성 (벡터 기반)\n",
    "semantic_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "print(f\"✓ SemanticRetriever 생성 완료 (k=5)\")\n",
    "\n",
    "# 3. EnsembleRetriever로 결합\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, semantic_retriever],\n",
    "    weights=[0.5, 0.5]  # 동일한 가중치\n",
    ")\n",
    "\n",
    "print(f\"✓ EnsembleRetriever 생성 완료 (weights=[0.5, 0.5])\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✅ 초기화 완료\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"PDF 문서 수: {len(pdf_documents)}개\")\n",
    "print(f\"컬렉션 이름: {CHROMA_COLLECTION_NAME}\")\n",
    "print(f\"저장 위치: {CHROMA_PERSIST_DIR}\")\n",
    "print(f\"Retriever 구성: BM25 (50%) + Semantic (50%)\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 노드 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_startup(state: AgentState) -> AgentState:\n",
    "    \"\"\"다음 평가할 스타트업 선택\"\"\"\n",
    "    idx = state.get(\"processing_index\", 0)\n",
    "    \n",
    "    if idx < len(state[\"startup_names\"]):\n",
    "        state[\"current_startup\"] = state[\"startup_names\"][idx]\n",
    "        # processing_index는 여기서 업데이트하지 않음 (evaluate에서 업데이트)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[{idx+1}/{len(state['startup_names'])}] {state['current_startup']} 평가 시작\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def crawl_web_data(state: AgentState) -> AgentState:\n",
    "    \"\"\"웹에서 스타트업 정보 크롤링\"\"\"\n",
    "    startup_name = state[\"current_startup\"]\n",
    "    \n",
    "    # 웹 크롤링\n",
    "    web_data = crawl_startup_info(startup_name, max_results=5)\n",
    "    state[\"web_data\"] = web_data\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def retrieve_tech_info(state: AgentState) -> AgentState:\n",
    "    \"\"\"PDF 문서에서 관련 기술 정보 검색\"\"\"\n",
    "    startup_name = state[\"current_startup\"]\n",
    "    \n",
    "    # 검색 쿼리 구성 (스타트업 특성 고려)\n",
    "    query = f\"{startup_name} AI 기술 혁신 스타트업 투자 평가 경쟁력\"\n",
    "    \n",
    "    print(f\"\\nPDF 문서에서 관련 정보 검색 중...\")\n",
    "    # EnsembleRetriever로 검색 수행\n",
    "    retrieved_docs = ensemble_retriever.get_relevant_documents(query)\n",
    "    \n",
    "    state[\"retrieved_docs\"] = retrieved_docs\n",
    "    print(f\"검색 완료: {len(retrieved_docs)}개 문서 검색됨\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def evaluate_technology(state: AgentState) -> AgentState:\n",
    "    \"\"\"웹 데이터와 PDF 정보를 바탕으로 기술력 평가\"\"\"\n",
    "    startup_name = state[\"current_startup\"]\n",
    "    web_data = state.get(\"web_data\", \"정보 없음\")\n",
    "    docs = state[\"retrieved_docs\"]\n",
    "    current_index = state.get(\"processing_index\", 0)\n",
    "    \n",
    "    # 이미 평가된 기업들의 점수 확인\n",
    "    existing_evaluations = state.get(\"tech_evaluations\", [])\n",
    "    existing_scores = [e['기술_점수'] for e in existing_evaluations if isinstance(e, dict)]\n",
    "    \n",
    "    # PDF 문서를 컨텍스트로 결합\n",
    "    pdf_context = \"\\n\\n\".join([doc.page_content for doc in docs[:3]])  # 상위 3개\n",
    "    \n",
    "    print(f\"\\nGPT-4o-mini를 사용하여 기술력 평가 중...\")\n",
    "    print(f\"  현재까지 평가 완료: {len(existing_evaluations)}개\")\n",
    "    \n",
    "    # 기존 점수 정보를 프롬프트에 강화\n",
    "    existing_scores_constraint = \"\"\n",
    "    if existing_scores:\n",
    "        scores_str = \", \".join(str(s) for s in existing_scores)\n",
    "        existing_scores_constraint = f\"\"\"\n",
    "### ⚠️ 중요한 제약 조건 ⚠️\n",
    "이미 평가한 기업들의 점수: [{scores_str}]\n",
    "\n",
    "**필수**: 새로운 기술_점수는 위 점수들과 **최소 5점 이상 차이**가 나야 합니다.\n",
    "- 이미 사용된 점수: {existing_scores}\n",
    "- 사용 금지 범위: {', '.join(f'{s}±4점' for s in existing_scores)}\n",
    "- 각 기업의 실제 강점과 약점을 반영하여 차별화된 점수를 부여하세요.\n",
    "\"\"\"\n",
    "    \n",
    "    # 평가 프롬프트 (단계별 세부 평가 요구)\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"당신은 AI 스타트업 투자 전문가입니다. \n",
    "주어진 웹 정보와 업계 트렌드 문서를 바탕으로 스타트업의 기술력을 객관적으로 평가하세요.\n",
    "\n",
    "## 평가 기준 (단계별 평가):\n",
    "\n",
    "**1단계: 각 항목별 점수 산정**\n",
    "- 기술의 혁신성 (0-30점): AI 기술의 독창성, 차별화된 접근 방식\n",
    "- 기술의 완성도 (0-30점): 제품/서비스의 완성도, 실제 적용 사례\n",
    "- 시장 경쟁력 (0-20점): 경쟁사 대비 우위, 시장 포지셔닝\n",
    "- 특허/지식재산권 (0-10점): 특허, 논문, 기술 자산\n",
    "- 기술 확장 가능성 (0-10점): 스케일업 가능성, 다른 분야 적용\n",
    "\n",
    "**2단계: 총점 계산**\n",
    "위 5개 항목의 점수를 합산하여 최종 기술_점수를 도출하세요.\n",
    "\n",
    "**중요**: \n",
    "- 기업마다 명확히 차별화된 점수를 부여하세요\n",
    "- 모든 기업에게 비슷한 점수를 주지 마세요\n",
    "- 각 기업의 실제 강점과 약점을 정확히 반영하세요\"\"\"),\n",
    "        (\"user\", \"\"\"스타트업 이름: {startup_name}\n",
    "\n",
    "=== 웹에서 수집한 정보 ===\n",
    "{web_data}\n",
    "\n",
    "=== 업계 트렌드 및 참고 문서 ===\n",
    "{pdf_context}\n",
    "\n",
    "{existing_scores_constraint}\n",
    "\n",
    "위 정보를 바탕으로 **단계별로 평가**하고 다음 JSON 형식으로 결과를 작성하세요:\n",
    "\n",
    "{{\n",
    "    \"startup_name\": \"스타트업 이름\",\n",
    "    \"항목별_점수\": {{\n",
    "        \"혁신성\": 점수 (0-30),\n",
    "        \"완성도\": 점수 (0-30),\n",
    "        \"경쟁력\": 점수 (0-20),\n",
    "        \"특허\": 점수 (0-10),\n",
    "        \"확장성\": 점수 (0-10)\n",
    "    }},\n",
    "    \"기술_점수\": 총점 (0-100, 정수),\n",
    "    \"기술_분석_근거\": \"각 항목별 점수 산정 이유를 구체적으로 설명. 혁신성, 완성도, 경쟁력, 특허, 확장성 각각에 대해 웹 정보를 인용하여 상세히 분석\"\n",
    "}}\n",
    "\n",
    "**필수**: 기술_점수는 항목별_점수의 합과 일치해야 합니다.\"\"\")\n",
    "    ])\n",
    "    \n",
    "    # LLM 호출\n",
    "    chain = eval_prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"startup_name\": startup_name,\n",
    "        \"web_data\": web_data[:2000],  # 토큰 제한 고려\n",
    "        \"pdf_context\": pdf_context[:3000],\n",
    "        \"existing_scores_constraint\": existing_scores_constraint\n",
    "    })\n",
    "    \n",
    "    # JSON 파싱\n",
    "    try:\n",
    "        content = response.content\n",
    "        if \"```json\" in content:\n",
    "            content = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "        elif \"```\" in content:\n",
    "            content = content.split(\"```\")[1].split(\"```\")[0]\n",
    "        \n",
    "        evaluation = json.loads(content.strip())\n",
    "        \n",
    "        # 항목별 점수가 있으면 총점 검증\n",
    "        if \"항목별_점수\" in evaluation:\n",
    "            item_scores = evaluation[\"항목별_점수\"]\n",
    "            calculated_total = sum(item_scores.values())\n",
    "            reported_total = evaluation.get(\"기술_점수\", calculated_total)\n",
    "            \n",
    "            # 총점이 맞지 않으면 재계산\n",
    "            if abs(calculated_total - reported_total) > 1:\n",
    "                print(f\"  ⚠️ 점수 불일치 감지 (보고: {reported_total}, 계산: {calculated_total}) - 재계산된 값 사용\")\n",
    "                evaluation[\"기술_점수\"] = calculated_total\n",
    "        \n",
    "        print(f\"평가 완료: {evaluation['기술_점수']}점\")\n",
    "        \n",
    "        # 항목별 점수 출력\n",
    "        if \"항목별_점수\" in evaluation:\n",
    "            scores_breakdown = \", \".join([f\"{k}={v}\" for k, v in evaluation[\"항목별_점수\"].items()])\n",
    "            print(f\"  세부: {scores_breakdown}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"JSON 파싱 실패: {e}\")\n",
    "        print(f\"응답 내용: {response.content[:300]}\")\n",
    "        evaluation = {\n",
    "            \"startup_name\": startup_name,\n",
    "            \"기술_점수\": 50,  # 기본값\n",
    "            \"기술_분석_근거\": f\"평가 실패: {str(e)}\"\n",
    "        }\n",
    "    \n",
    "    # ★ 중요: 기존 리스트에 append (덮어쓰기 아님!)\n",
    "    current_evaluations = state.get(\"tech_evaluations\", [])\n",
    "    current_evaluations.append(evaluation)\n",
    "    state[\"tech_evaluations\"] = current_evaluations\n",
    "    \n",
    "    # processing_index 증가 (다음 기업으로)\n",
    "    state[\"processing_index\"] = current_index + 1\n",
    "    \n",
    "    print(f\"진행 상황: {state['processing_index']}/{len(state['startup_names'])} 완료\")\n",
    "    print(f\"  누적 평가 결과: {len(state['tech_evaluations'])}개\\n\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def check_completion(state: AgentState) -> str:\n",
    "    \"\"\"모든 스타트업 평가 완료 여부 확인\"\"\"\n",
    "    idx = state.get(\"processing_index\", 0)\n",
    "    total = len(state.get(\"startup_names\", []))\n",
    "    \n",
    "    print(f\"[check_completion] 현재 인덱스: {idx}, 전체: {total}\")\n",
    "    \n",
    "    if idx < total:\n",
    "        return \"continue\"  # 다음 스타트업 평가\n",
    "    else:\n",
    "        return \"end\"  # 모든 평가 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Langgraph 워크플로우 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "워크플로우 구성 완료!\n",
      "순서: select_startup -> crawl_web -> retrieve_info -> evaluate -> [반복 or 종료]\n"
     ]
    }
   ],
   "source": [
    "# StateGraph 생성\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"select_startup\", select_next_startup)\n",
    "workflow.add_node(\"crawl_web\", crawl_web_data)\n",
    "workflow.add_node(\"retrieve_info\", retrieve_tech_info)\n",
    "workflow.add_node(\"evaluate\", evaluate_technology)\n",
    "\n",
    "# 엣지 설정\n",
    "workflow.set_entry_point(\"select_startup\")\n",
    "workflow.add_edge(\"select_startup\", \"crawl_web\")\n",
    "workflow.add_edge(\"crawl_web\", \"retrieve_info\")\n",
    "workflow.add_edge(\"retrieve_info\", \"evaluate\")\n",
    "\n",
    "# 조건부 엣지 (평가 완료 후 다음 스타트업으로 이동 또는 종료)\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate\",\n",
    "    check_completion,\n",
    "    {\n",
    "        \"continue\": \"select_startup\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"\\n워크플로우 구성 완료!\")\n",
    "print(\"순서: select_startup -> crawl_web -> retrieve_info -> evaluate -> [반복 or 종료]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 에이전트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "AI 스타트업 기술 평가 에이전트 시작\n",
      "평가 대상: 5개 기업\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "[1/5] 리브 애니웨어 평가 시작\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "웹 검색 시작: 리브 애니웨어\n",
      "============================================================\n",
      "  [Tavily] 검색 중...\n",
      "    쿼리 1: 리브 애니웨어 스타트업 기술 혁신\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    쿼리 2: 리브 애니웨어 AI 투자 비즈니스\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    총 12개 항목 수집\n",
      "✓ Tavily 검색 성공\n",
      "\n",
      "\n",
      "PDF 문서에서 관련 정보 검색 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKAX\\AppData\\Local\\Temp\\ipykernel_16932\\2591897961.py:35: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = ensemble_retriever.get_relevant_documents(query)\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 완료: 8개 문서 검색됨\n",
      "\n",
      "GPT-4o-mini를 사용하여 기술력 평가 중...\n",
      "  현재까지 평가 완료: 0개\n",
      "평가 완료: 85점\n",
      "  세부: 혁신성=25, 완성도=28, 경쟁력=18, 특허=6, 확장성=8\n",
      "진행 상황: 1/5 완료\n",
      "  누적 평가 결과: 1개\n",
      "\n",
      "[check_completion] 현재 인덱스: 1, 전체: 5\n",
      "\n",
      "============================================================\n",
      "[2/5] 어딩 평가 시작\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "웹 검색 시작: 어딩\n",
      "============================================================\n",
      "  [Tavily] 검색 중...\n",
      "    쿼리 1: 어딩 스타트업 기술 혁신\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    쿼리 2: 어딩 AI 투자 비즈니스\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    총 12개 항목 수집\n",
      "✓ Tavily 검색 성공\n",
      "\n",
      "\n",
      "PDF 문서에서 관련 정보 검색 중...\n",
      "검색 완료: 9개 문서 검색됨\n",
      "\n",
      "GPT-4o-mini를 사용하여 기술력 평가 중...\n",
      "  현재까지 평가 완료: 1개\n",
      "평가 완료: 84점\n",
      "  세부: 혁신성=25, 완성도=28, 경쟁력=18, 특허=5, 확장성=8\n",
      "진행 상황: 2/5 완료\n",
      "  누적 평가 결과: 2개\n",
      "\n",
      "[check_completion] 현재 인덱스: 2, 전체: 5\n",
      "\n",
      "============================================================\n",
      "[3/5] 트립비토즈 평가 시작\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "웹 검색 시작: 트립비토즈\n",
      "============================================================\n",
      "  [Tavily] 검색 중...\n",
      "    쿼리 1: 트립비토즈 스타트업 기술 혁신\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    쿼리 2: 트립비토즈 AI 투자 비즈니스\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    총 12개 항목 수집\n",
      "✓ Tavily 검색 성공\n",
      "\n",
      "\n",
      "PDF 문서에서 관련 정보 검색 중...\n",
      "검색 완료: 8개 문서 검색됨\n",
      "\n",
      "GPT-4o-mini를 사용하여 기술력 평가 중...\n",
      "  현재까지 평가 완료: 2개\n",
      "평가 완료: 81점\n",
      "  세부: 혁신성=25, 완성도=28, 경쟁력=15, 특허=5, 확장성=8\n",
      "진행 상황: 3/5 완료\n",
      "  누적 평가 결과: 3개\n",
      "\n",
      "[check_completion] 현재 인덱스: 3, 전체: 5\n",
      "\n",
      "============================================================\n",
      "[4/5] 트립소다 평가 시작\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "웹 검색 시작: 트립소다\n",
      "============================================================\n",
      "  [Tavily] 검색 중...\n",
      "    쿼리 1: 트립소다 스타트업 기술 혁신\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    쿼리 2: 트립소다 AI 투자 비즈니스\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    총 12개 항목 수집\n",
      "✓ Tavily 검색 성공\n",
      "\n",
      "\n",
      "PDF 문서에서 관련 정보 검색 중...\n",
      "검색 완료: 8개 문서 검색됨\n",
      "\n",
      "GPT-4o-mini를 사용하여 기술력 평가 중...\n",
      "  현재까지 평가 완료: 3개\n",
      "평가 완료: 84점\n",
      "  세부: 혁신성=25, 완성도=28, 경쟁력=18, 특허=5, 확장성=8\n",
      "진행 상황: 4/5 완료\n",
      "  누적 평가 결과: 4개\n",
      "\n",
      "[check_completion] 현재 인덱스: 4, 전체: 5\n",
      "\n",
      "============================================================\n",
      "[5/5] 하이어플레이스 평가 시작\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "웹 검색 시작: 하이어플레이스\n",
      "============================================================\n",
      "  [Tavily] 검색 중...\n",
      "    쿼리 1: 하이어플레이스 스타트업 기술 혁신\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    쿼리 2: 하이어플레이스 AI 투자 비즈니스\n",
      "      ✓ AI 요약 수집\n",
      "      ✓ 5개 출처 발견\n",
      "    총 12개 항목 수집\n",
      "✓ Tavily 검색 성공\n",
      "\n",
      "\n",
      "PDF 문서에서 관련 정보 검색 중...\n",
      "검색 완료: 9개 문서 검색됨\n",
      "\n",
      "GPT-4o-mini를 사용하여 기술력 평가 중...\n",
      "  현재까지 평가 완료: 4개\n",
      "평가 완료: 70점\n",
      "  세부: 혁신성=25, 완성도=20, 경쟁력=15, 특허=5, 확장성=5\n",
      "진행 상황: 5/5 완료\n",
      "  누적 평가 결과: 5개\n",
      "\n",
      "[check_completion] 현재 인덱스: 5, 전체: 5\n",
      "\n",
      "============================================================\n",
      "전체 평가 완료\n",
      "최종 평가 결과 수: 5개\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 평가할 스타트업 리스트\n",
    "startups_to_evaluate = [\n",
    "    \"리브 애니웨어\",\n",
    "    \"어딩\",\n",
    "    \"트립비토즈\",\n",
    "    \"트립소다\",\n",
    "    \"하이어플레이스\"\n",
    "]\n",
    "\n",
    "# 초기 상태 설정 (명확한 초기화)\n",
    "initial_state = {\n",
    "    \"startup_names\": startups_to_evaluate,\n",
    "    \"current_startup\": \"\",\n",
    "    \"web_data\": \"\",\n",
    "    \"retrieved_docs\": [],\n",
    "    \"tech_evaluations\": [],  # 빈 리스트로 명확히 초기화\n",
    "    \"processing_index\": 0,\n",
    "    \"vectorstore_ready\": True\n",
    "}\n",
    "\n",
    "# 에이전트 실행\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AI 스타트업 기술 평가 에이전트 시작\")\n",
    "print(f\"평가 대상: {len(startups_to_evaluate)}개 기업\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 그래프 재컴파일 (이전 상태 초기화)\n",
    "app = workflow.compile()\n",
    "\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"전체 평가 완료\")\n",
    "print(f\"최종 평가 결과 수: {len(result['tech_evaluations'])}개\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "############################################################\n",
      "총 5개 스타트업 평가 완료\n",
      "############################################################\n",
      "\n",
      "\n",
      "============================================================\n",
      "[1] 리브 애니웨어\n",
      "============================================================\n",
      "\n",
      "기술 점수: 85/100점\n",
      "\n",
      "분석 근거:\n",
      "리브 애니웨어는 단기 임대 숙소 예약 플랫폼으로, 혁신적인 접근 방식으로 주목받고 있으며, 2023년 아기유니콘으로 선정된 점에서 기술의 혁신성을 높이 평가할 수 있습니다. (혁신성: 25점) 또한, 50억 원 규모의 시리즈 A 투자를 유치하고, 도시·지역혁신 산업박람회에서 최우수상을 수상한 바 있어, 제품의 완성도 또한 높습니다. (완성도: 28점) 시장 경쟁력 측면에서는 단기 임대 숙소 시장에서의 포지셔닝이 긍정적이나, 경쟁사 대비 우위가 명확하게 드러나지 않아 다소 낮은 점수를 부여했습니다. (경쟁력: 18점) 특허와 관련된 정보는 부족하나, R&D 과제와 보유 특허 정보가 언급되었으므로 일정 부분 점수를 부여했습니다. (특허: 6점) 마지막으로, 리브 애니웨어는 단기 임대 시장을 넘어 장기 거주로의 확장 가능성을 보여주고 있어, 확장성에 대한 점수는 비교적 높게 평가했습니다. (확장성: 8점)\n",
      "\n",
      "\n",
      "============================================================\n",
      "[2] 어딩\n",
      "============================================================\n",
      "\n",
      "기술 점수: 84/100점\n",
      "\n",
      "분석 근거:\n",
      "어딩은 여행업계의 디지털 혁신을 주도하는 SaaS 기반 플랫폼을 제공하여 여행사의 업무를 효율화하고 있습니다. 혁신성 측면에서, 어딩은 여행산업에 대한 깊은 이해와 디지털 기술의 결합을 통해 차별화된 접근 방식을 보여주고 있으며, 이는 25점으로 평가됩니다. 완성도는 실제로 중소형 여행사들이 저렴하게 여행 상품을 관리할 수 있는 환경을 제공하고 있다는 점에서 28점으로 높게 평가됩니다. 시장 경쟁력은 중소형 여행사들 사이에서의 수요가 증가하고 있지만, 대기업과의 경쟁에서 다소 약점을 보일 수 있어 18점으로 설정했습니다. 특허와 관련된 정보는 부족하지만, 기술 자산이 존재하는 것으로 보아 5점을 부여했습니다. 마지막으로, 어딩의 기술 확장 가능성은 다른 분야로의 적용 가능성이 보이지만 아직 초기 단계이므로 8점으로 평가하였습니다.\n",
      "\n",
      "\n",
      "============================================================\n",
      "[3] 트립비토즈\n",
      "============================================================\n",
      "\n",
      "기술 점수: 81/100점\n",
      "\n",
      "분석 근거:\n",
      "트립비토즈는 AI 기반의 추천 시스템을 통해 고객의 여행 경험을 개인화하는 혁신적인 접근 방식을 가지고 있습니다. 이는 '여행의 감성'을 중심으로 한 기술 결합을 통해 이루어지며, 고객 중심의 AI 추천 시스템은 차별화된 서비스로 평가됩니다. 완성도 측면에서는 실제 사용자 생성 콘텐츠를 활용한 맞춤형 숙소 추천 서비스가 성공적으로 운영되고 있어 높은 점수를 부여했습니다. 그러나 시장 경쟁력은 다소 낮은 편으로, 경쟁사 대비 명확한 우위를 점하고 있지 않다는 점에서 15점을 부여했습니다. 특허와 관련된 정보는 부족하여 5점을 부여했으며, 기술 확장 가능성은 다른 지역으로의 서비스 확장 및 다양한 여행 관련 서비스로의 적용 가능성으로 인해 8점을 부여했습니다.\n",
      "\n",
      "\n",
      "============================================================\n",
      "[4] 트립소다\n",
      "============================================================\n",
      "\n",
      "기술 점수: 84/100점\n",
      "\n",
      "분석 근거:\n",
      "트립소다는 여행 커뮤니티 커머스 플랫폼으로, MZ세대 여행자들을 타겟으로 하여 독창적인 접근 방식을 가지고 있습니다. 이는 혁신성에서 25점을 부여한 이유입니다. 제품의 완성도는 최근 7억원의 기술 지원을 받았고, 글로벌 시장 확장을 위한 프로그램에 선정된 점에서 28점을 부여했습니다. 시장 경쟁력은 유니콘 기업으로 인정받았지만, 여행 커뮤니티 분야에서의 경쟁이 치열하므로 18점을 부여했습니다. 특허 및 지식재산권은 명확한 정보가 부족하여 5점을 부여했습니다. 마지막으로, 기술 확장 가능성은 글로벌 시장 진출을 목표로 하고 있으나, 다른 분야로의 적용 가능성은 아직 명확하지 않아 8점을 부여했습니다.\n",
      "\n",
      "\n",
      "============================================================\n",
      "[5] 하이어플레이스\n",
      "============================================================\n",
      "\n",
      "기술 점수: 70/100점\n",
      "\n",
      "분석 근거:\n",
      "하이어플레이스는 AI 기술 혁신에 중점을 두고 있으며, 서울의 오픈 이노베이션 정책을 통해 글로벌 스타트업 성장 지원을 받고 있습니다. 혁신성 점수는 25점으로, AI 기술의 독창성과 차별화된 접근 방식이 인정받고 있음을 반영합니다. 완성도는 20점으로, 제품이나 서비스의 실제 적용 사례에 대한 정보가 부족하여 다소 낮게 평가되었습니다. 경쟁력은 15점으로, 서울의 스타트업 생태계 내에서의 위치는 긍정적이나, 구체적인 경쟁사 대비 우위에 대한 정보가 부족합니다. 특허는 5점으로, 관련된 특허나 기술 자산에 대한 정보가 부족하여 낮게 평가되었습니다. 마지막으로 확장성은 5점으로, 스케일업 가능성에 대한 정보가 부족하여 점수가 낮습니다. 전체적으로 하이어플레이스는 기술적으로 유망하지만, 구체적인 성과나 사례가 부족하여 점수가 제한적입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 결과 출력\n",
    "evaluations = result[\"tech_evaluations\"]\n",
    "\n",
    "print(f\"\\n\\n{'#'*60}\")\n",
    "print(f\"총 {len(evaluations)}개 스타트업 평가 완료\")\n",
    "print(f\"{'#'*60}\\n\")\n",
    "\n",
    "for i, eval_data in enumerate(evaluations, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"[{i}] {eval_data['startup_name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n기술 점수: {eval_data['기술_점수']}/100점\")\n",
    "    print(f\"\\n분석 근거:\")\n",
    "    print(f\"{eval_data['기술_분석_근거']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 결과 저장 (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "평가 결과가 'tech_evaluation_results.json'에 저장되었습니다.\n",
      "\n",
      "=== 평가 요약 ===\n",
      "평균 점수: 73.8점\n",
      "최고 점수: 80점 - 트립비토즈\n",
      "최저 점수: 70점 - 하이어플레이스\n"
     ]
    }
   ],
   "source": [
    "# JSON 파일로 저장\n",
    "output_file = \"tech_evaluation_results.json\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(evaluations, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n평가 결과가 '{output_file}'에 저장되었습니다.\")\n",
    "\n",
    "# 요약 통계\n",
    "if evaluations:\n",
    "    scores = [e['기술_점수'] for e in evaluations]\n",
    "    print(f\"\\n=== 평가 요약 ===\")\n",
    "    print(f\"평균 점수: {sum(scores)/len(scores):.1f}점\")\n",
    "    print(f\"최고 점수: {max(scores)}점 - {evaluations[scores.index(max(scores))]['startup_name']}\")\n",
    "    print(f\"최저 점수: {min(scores)}점 - {evaluations[scores.index(min(scores))]['startup_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 추가 기능: 개별 스타트업 재평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_startup(startup_name: str):\n",
    "    \"\"\"단일 스타트업에 대한 기술 평가\"\"\"\n",
    "    single_state = {\n",
    "        \"startup_names\": [startup_name],\n",
    "        \"current_startup\": \"\",\n",
    "        \"web_data\": \"\",\n",
    "        \"retrieved_docs\": [],\n",
    "        \"tech_evaluations\": [],\n",
    "        \"processing_index\": 0,\n",
    "        \"vectorstore_ready\": True\n",
    "    }\n",
    "    \n",
    "    result = app.invoke(single_state)\n",
    "    return result[\"tech_evaluations\"][0]\n",
    "\n",
    "# 사용 예시\n",
    "# single_result = evaluate_single_startup(\"야놀자\")\n",
    "# print(json.dumps(single_result, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 성능 개선 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 성능 개선 옵션 ==========\n",
    "\n",
    "# 1. 더 많은 문서 검색 (k 값 조정)\n",
    "# bm25_retriever.k = 10\n",
    "# semantic_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "# ensemble_retriever = EnsembleRetriever(\n",
    "#     retrievers=[bm25_retriever, semantic_retriever],\n",
    "#     weights=[0.5, 0.5]\n",
    "# )\n",
    "\n",
    "# 2. BM25/Semantic 가중치 조정\n",
    "#    weights=[0.7, 0.3]: BM25 중시 (키워드 매칭)\n",
    "#    weights=[0.3, 0.7]: Semantic 중시 (의미적 유사성)\n",
    "#    weights=[0.5, 0.5]: 균형 (기본값)\n",
    "# ensemble_retriever = EnsembleRetriever(\n",
    "#     retrievers=[bm25_retriever, semantic_retriever],\n",
    "#     weights=[0.7, 0.3]  # BM25 중시\n",
    "# )\n",
    "\n",
    "# 3. 웹 크롤링 결과 수 조정\n",
    "#    max_results=10 으로 더 많은 정보 수집\n",
    "\n",
    "# 4. 다른 임베딩 모델 사용\n",
    "# embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "# 5. PDF 청킹 전략 변경\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=1500,\n",
    "#     chunk_overlap=300\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-5k19pLvO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
