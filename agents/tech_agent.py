"""
AI ìŠ¤íƒ€íŠ¸ì—… ê¸°ìˆ  í‰ê°€ ì—ì´ì „íŠ¸
Langgraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ í¬ë¡¤ë§ + PDF ë¶„ì„ì„ í†µí•œ ê¸°ìˆ ë ¥ í‰ê°€
"""

import os
import sys
from pathlib import Path
from typing import TypedDict, List, Dict
import json
import time

from langchain_openai import ChatOpenAI
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.retrievers import BM25Retriever
from langchain_classic.retrievers import EnsembleRetriever
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate

from langgraph.graph import StateGraph, END
from dotenv import load_dotenv
from tavily import TavilyClient

from state.tech_state import TechState

load_dotenv()


# ========== TypedDict ì •ì˜ ==========
class WorkflowState(TypedDict):
    """LangGraph ì›Œí¬í”Œë¡œìš° ìƒíƒœ"""
    startup_names: List[str]
    current_startup: str
    web_data: str
    retrieved_docs: List[Document]
    tech_evaluations: List[Dict]  # List[TechState]
    processing_index: int
    vectorstore_ready: bool


# ========== TechAgent í´ë˜ìŠ¤ ==========

class TechAgent:
    """
    AI ìŠ¤íƒ€íŠ¸ì—… ê¸°ìˆ  í‰ê°€ ì—ì´ì „íŠ¸

    ì‚¬ìš©ë²•:
        agent = TechAgent(startups_to_evaluate="ì–´ë”©")
        result = agent.get_tech_result()  # TechState ë°˜í™˜
        
        print(result['company_name'])
        print(result['technology_score'])
        print(result['category_scores'])
    """

    def __init__(self, startups_to_evaluate: str | List[str]):
        """
        Args:
            startups_to_evaluate: í‰ê°€í•  ìŠ¤íƒ€íŠ¸ì—… ì´ë¦„ (ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)
        """
        # ìŠ¤íƒ€íŠ¸ì—… ë¦¬ìŠ¤íŠ¸ ì„¤ì •
        if isinstance(startups_to_evaluate, str):
            self.startup_names = [startups_to_evaluate]
        else:
            self.startup_names = startups_to_evaluate

        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ê³„ì‚° (agents í´ë” ê¸°ì¤€)
        # agents/tech_agent.py -> agents -> root
        root = os.path.normpath(os.path.join(os.path.dirname(__file__), os.pardir))
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(model="gpt-4o", temperature=0.3)
        self.embeddings = OllamaEmbeddings(model="nomic-embed-text")

        # ChromaDB ê²½ë¡œ
        self.chroma_persist_dir = os.path.join(root, "rag", "tech")
        self.chroma_collection_name = "startup_tech_db"

        # VectorStore ë° Retriever ì´ˆê¸°í™”
        self.vectorstore = None
        self.ensemble_retriever = None

        # Workflow ì´ˆê¸°í™”
        self.app = None

        print(f"\n{'='*60}")
        print(f"TechAgent ì´ˆê¸°í™”")
        print(f"{'='*60}")
        print(f"í‰ê°€ ëŒ€ìƒ: {', '.join(self.startup_names)}")
        print(f"ChromaDB ê²½ë¡œ: {self.chroma_persist_dir}")
        print(f"{'='*60}\n")

    def _load_pdf_for_bm25(self) -> List[Document]:
        """
        BM25 Retrieverìš© PDF ë¬¸ì„œ ë¡œë“œ
        (ê¸°ì¡´ ChromaDB ì¸ë±ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ì§€ ì•Šê³ , PDFë¥¼ ì§ì ‘ ë¡œë“œ)
        """
        # agents/tech_agent.py -> agents -> root
        root = os.path.normpath(os.path.join(os.path.dirname(__file__), os.pardir))
        data_dir = os.path.join(root, "data")
        
        # indexerì™€ ë™ì¼í•œ íŒŒì¼ ëª©ë¡
        pdf_files = [
            os.path.join(data_dir, "ê¸°ìˆ ìš”ì•½_ì „ì²´_ê¸°ì—…_ì¸í„°ë·°.pdf"),
            os.path.join(data_dir, "ì‹œì¥ì„±ë¶„ì„_ìŠ¤íƒ€íŠ¸ì—…_ì‹œì¥ì „ëµ_ë°_ìƒíƒœê³„.pdf"),
            os.path.join(data_dir, "ê¸°ì—…ë¹„êµ.pdf")
        ]
        
        print("PDF ë¬¸ì„œ ë¡œë“œ ì¤‘ (BM25 ì¸ë±ìŠ¤ìš©)...")
        all_documents = []
        
        for pdf_file in pdf_files:
            if not os.path.exists(pdf_file):
                continue
                
            try:
                loader = PyPDFLoader(str(pdf_file))
                documents = loader.load()
                
                for doc in documents:
                    doc.metadata["source_file"] = os.path.basename(pdf_file)
                    doc.metadata["source_type"] = "pdf"
                
                all_documents.extend(documents)
            except Exception as e:
                print(f"  PDF ë¡œë“œ ì‹¤íŒ¨ ({os.path.basename(pdf_file)}): {e}")
        
        # ì²­í‚¹
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        split_documents = text_splitter.split_documents(all_documents)
        print(f"  âœ“ {len(split_documents)}ê°œì˜ ì²­í¬ ìƒì„± ì™„ë£Œ\n")
        
        return split_documents

    def _initialize_vectorstore(self):
        """VectorStore ë° EnsembleRetriever ì´ˆê¸°í™”"""
        print(f"{'='*60}")
        print(f"VectorStore ì´ˆê¸°í™”")
        print(f"{'='*60}\n")

        # ChromaDB ì¡´ì¬ í™•ì¸
        if not os.path.exists(self.chroma_persist_dir) or not os.path.isdir(self.chroma_persist_dir):
            raise FileNotFoundError(
                f"ChromaDB ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.chroma_persist_dir}\n"
                f"ë¨¼ì € indexer_build.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”:\n"
                f"  python rag/tech/indexer_build.py --force"
            )
        
        # ê¸°ì¡´ ChromaDB ë¡œë“œ
        print("ğŸ“‚ ê¸°ì¡´ VectorStore ë¡œë“œ ì¤‘...")
        self.vectorstore = Chroma(
            collection_name=self.chroma_collection_name,
            embedding_function=self.embeddings,
            persist_directory=self.chroma_persist_dir
        )
        print("âœ“ VectorStore ë¡œë“œ ì™„ë£Œ\n")
        
        # BM25ìš© PDF ë¬¸ì„œ ë¡œë“œ
        pdf_documents = self._load_pdf_for_bm25()

        # EnsembleRetriever êµ¬ì„±
        print(f"{'='*60}")
        print(f"EnsembleRetriever êµ¬ì„± ì¤‘...")
        print(f"{'='*60}\n")

        bm25_retriever = BM25Retriever.from_documents(pdf_documents)
        bm25_retriever.k = 5

        semantic_retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 5}
        )

        self.ensemble_retriever = EnsembleRetriever(
            retrievers=[bm25_retriever, semantic_retriever],
            weights=[0.5, 0.5]
        )

        print("âœ“ BM25Retriever ìƒì„± ì™„ë£Œ (k=5)")
        print("âœ“ SemanticRetriever ìƒì„± ì™„ë£Œ (k=5)")
        print("âœ“ EnsembleRetriever ìƒì„± ì™„ë£Œ (weights=[0.5, 0.5])\n")

    def _crawl_with_tavily(self, startup_name: str, max_results: int = 5) -> str:
        """Tavily APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰"""
        api_key = os.getenv("TAVILY_API_KEY")
        if not api_key:
            raise ValueError("TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        print(f"  [Tavily] ê²€ìƒ‰ ì¤‘...")
        client = TavilyClient(api_key=api_key)

        queries = [
            f"{startup_name} ìŠ¤íƒ€íŠ¸ì—… ê¸°ìˆ  í˜ì‹ ",
            f"{startup_name} AI íˆ¬ì ë¹„ì¦ˆë‹ˆìŠ¤"
        ]

        collected_text = []

        for idx, query in enumerate(queries, 1):
            try:
                print(f"    ì¿¼ë¦¬ {idx}: {query}")

                response = client.search(
                    query=query,
                    search_depth="basic",
                    max_results=max_results,
                    include_answer=True,
                    include_raw_content=False,
                    include_domains=None,
                    days=365
                )

                if response.get('answer'):
                    collected_text.append(f"[AI ìš”ì•½] {response['answer']}")
                    print(f"      âœ“ AI ìš”ì•½ ìˆ˜ì§‘")

                results = response.get('results', [])
                print(f"      âœ“ {len(results)}ê°œ ì¶œì²˜ ë°œê²¬")

                for result in results:
                    title = result.get('title', '')
                    content = result.get('content', '')
                    url = result.get('url', '')
                    score = result.get('score', 0)

                    if content and len(content) > 50:
                        collected_text.append(
                            f"[ì¶œì²˜: {url}]\nì œëª©: {title}\në‚´ìš©: {content}\nê´€ë ¨ì„±: {score:.2f}"
                        )

                time.sleep(0.3)
            except Exception as e:
                print(f"      âœ— ì¿¼ë¦¬ ì‹¤íŒ¨: {str(e)[:50]}")
                continue

        if not collected_text:
            raise ValueError("Tavilyì—ì„œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        result_text = "\n\n".join(collected_text)
        print(f"    ì´ {len(collected_text)}ê°œ í•­ëª© ìˆ˜ì§‘")
        return result_text

    def _crawl_startup_info(self, startup_name: str, max_results: int = 5) -> str:
        """ìŠ¤íƒ€íŠ¸ì—… ì •ë³´ë¥¼ ì›¹ì—ì„œ í¬ë¡¤ë§"""
        print(f"\n{'='*60}")
        print(f"ì›¹ ê²€ìƒ‰ ì‹œì‘: {startup_name}")
        print(f"{'='*60}")

        try:
            result = self._crawl_with_tavily(startup_name, max_results)
            if result and len(result) > 100:
                print(f"âœ“ Tavily ê²€ìƒ‰ ì„±ê³µ\n")
                return result
        except Exception as e:
            print(f"âœ— Tavily ì˜¤ë¥˜: {str(e)[:50]}")
            return f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"

    def _build_workflow(self):
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""

        def select_next_startup(state: WorkflowState) -> WorkflowState:
            """ë‹¤ìŒ í‰ê°€í•  ìŠ¤íƒ€íŠ¸ì—… ì„ íƒ"""
            idx = state.get("processing_index", 0)

            if idx < len(state["startup_names"]):
                state["current_startup"] = state["startup_names"][idx]
                print(f"\n{'='*60}")
                print(f"[{idx+1}/{len(state['startup_names'])}] {state['current_startup']} í‰ê°€ ì‹œì‘")
                print(f"{'='*60}")

            return state

        def crawl_web_data(state: WorkflowState) -> WorkflowState:
            """ì›¹ì—ì„œ ìŠ¤íƒ€íŠ¸ì—… ì •ë³´ í¬ë¡¤ë§"""
            startup_name = state["current_startup"]
            web_data = self._crawl_startup_info(startup_name, max_results=5)
            state["web_data"] = web_data
            return state

        def retrieve_tech_info(state: WorkflowState) -> WorkflowState:
            """PDF ë¬¸ì„œì—ì„œ ê´€ë ¨ ê¸°ìˆ  ì •ë³´ ê²€ìƒ‰"""
            startup_name = state["current_startup"]
            query = f"{startup_name} AI ê¸°ìˆ  í˜ì‹  ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì í‰ê°€ ê²½ìŸë ¥"

            print(f"\nPDF ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
            retrieved_docs = self.ensemble_retriever.invoke(query)

            state["retrieved_docs"] = retrieved_docs
            print(f"ê²€ìƒ‰ ì™„ë£Œ: {len(retrieved_docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")

            return state

        def evaluate_technology(state: WorkflowState) -> WorkflowState:
            """ì›¹ ë°ì´í„°ì™€ PDF ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ ë ¥ í‰ê°€"""
            startup_name = state["current_startup"]
            web_data = state.get("web_data", "ì •ë³´ ì—†ìŒ")
            docs = state["retrieved_docs"]
            current_index = state.get("processing_index", 0)

            existing_evaluations = state.get("tech_evaluations", [])
            existing_scores = [
                e.get('technology_score', 0) 
                for e in existing_evaluations 
                if isinstance(e, dict)
            ]

            pdf_context = "\n\n".join([doc.page_content for doc in docs[:3]])

            print(f"\nGPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ìˆ ë ¥ í‰ê°€ ì¤‘...")
            print(f"  í˜„ì¬ê¹Œì§€ í‰ê°€ ì™„ë£Œ: {len(existing_evaluations)}ê°œ")

            existing_scores_constraint = ""
            if existing_scores:
                scores_str = ", ".join(str(s) for s in existing_scores)
                existing_scores_constraint = f"""
### âš ï¸ ì¤‘ìš”í•œ ì œì•½ ì¡°ê±´ âš ï¸
ì´ë¯¸ í‰ê°€í•œ ê¸°ì—…ë“¤ì˜ ì ìˆ˜: [{scores_str}]

**í•„ìˆ˜**: ìƒˆë¡œìš´ technology_scoreëŠ” ìœ„ ì ìˆ˜ë“¤ê³¼ **ìµœì†Œ 5ì  ì´ìƒ ì°¨ì´**ê°€ ë‚˜ì•¼ í•©ë‹ˆë‹¤.
- ì´ë¯¸ ì‚¬ìš©ëœ ì ìˆ˜: {existing_scores}
- ì‚¬ìš© ê¸ˆì§€ ë²”ìœ„: {', '.join(f'{s}Â±4ì ' for s in existing_scores)}
- ê° ê¸°ì—…ì˜ ì‹¤ì œ ê°•ì ê³¼ ì•½ì ì„ ë°˜ì˜í•˜ì—¬ ì°¨ë³„í™”ëœ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”.
"""

            eval_prompt = ChatPromptTemplate.from_messages([
                ("system", """ë‹¹ì‹ ì€ AI ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì›¹ ì •ë³´ì™€ ì—…ê³„ íŠ¸ë Œë“œ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤íƒ€íŠ¸ì—…ì˜ ê¸°ìˆ ë ¥ì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

## í‰ê°€ ê¸°ì¤€ (ë‹¨ê³„ë³„ í‰ê°€):

**1ë‹¨ê³„: ê° í•­ëª©ë³„ ì ìˆ˜ ì‚°ì •**
- innovation (í˜ì‹ ì„±) (0-30ì ): AI ê¸°ìˆ ì˜ ë…ì°½ì„±, ì°¨ë³„í™”ëœ ì ‘ê·¼ ë°©ì‹
- completeness (ì™„ì„±ë„) (0-30ì ): ì œí’ˆ/ì„œë¹„ìŠ¤ì˜ ì™„ì„±ë„, ì‹¤ì œ ì ìš© ì‚¬ë¡€
- competitiveness (ê²½ìŸë ¥) (0-20ì ): ê²½ìŸì‚¬ ëŒ€ë¹„ ìš°ìœ„, ì‹œì¥ í¬ì§€ì…”ë‹
- patent (íŠ¹í—ˆ) (0-10ì ): íŠ¹í—ˆ, ë…¼ë¬¸, ê¸°ìˆ  ìì‚°
- scalability (í™•ì¥ì„±) (0-10ì ): ìŠ¤ì¼€ì¼ì—… ê°€ëŠ¥ì„±, ë‹¤ë¥¸ ë¶„ì•¼ ì ìš©

**2ë‹¨ê³„: ì´ì  ê³„ì‚°**
ìœ„ 5ê°œ í•­ëª©ì˜ ì ìˆ˜ë¥¼ í•©ì‚°í•˜ì—¬ ìµœì¢… technology_scoreë¥¼ ë„ì¶œí•˜ì„¸ìš”.

**ì¤‘ìš”**:
- ê¸°ì—…ë§ˆë‹¤ ëª…í™•íˆ ì°¨ë³„í™”ëœ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”
- ëª¨ë“  ê¸°ì—…ì—ê²Œ ë¹„ìŠ·í•œ ì ìˆ˜ë¥¼ ì£¼ì§€ ë§ˆì„¸ìš”
- ê° ê¸°ì—…ì˜ ì‹¤ì œ ê°•ì ê³¼ ì•½ì ì„ ì •í™•íˆ ë°˜ì˜í•˜ì„¸ìš”"""),
                ("user", """ìŠ¤íƒ€íŠ¸ì—… ì´ë¦„: {startup_name}

=== ì›¹ì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´ ===
{web_data}

=== ì—…ê³„ íŠ¸ë Œë“œ ë° ì°¸ê³  ë¬¸ì„œ ===
{pdf_context}

{existing_scores_constraint}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë‹¨ê³„ë³„ë¡œ í‰ê°€**í•˜ê³  ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì‘ì„±í•˜ì„¸ìš”:

```json
{{
    "company_name": "ìŠ¤íƒ€íŠ¸ì—… ì´ë¦„",
    "category_scores": {{
        "innovation": ì ìˆ˜ (0-30, ì •ìˆ˜),
        "completeness": ì ìˆ˜ (0-30, ì •ìˆ˜),
        "competitiveness": ì ìˆ˜ (0-20, ì •ìˆ˜),
        "patent": ì ìˆ˜ (0-10, ì •ìˆ˜),
        "scalability": ì ìˆ˜ (0-10, ì •ìˆ˜)
    }},
    "technology_score": ì´ì  (0-100, ì •ìˆ˜),
    "technology_analysis_basis": "ê° í•­ëª©ë³„ ì ìˆ˜ ì‚°ì • ì´ìœ ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…. í˜ì‹ ì„±, ì™„ì„±ë„, ê²½ìŸë ¥, íŠ¹í—ˆ, í™•ì¥ì„± ê°ê°ì— ëŒ€í•´ ì›¹ ì •ë³´ë¥¼ ì¸ìš©í•˜ì—¬ ìƒì„¸íˆ ë¶„ì„"
}}
```

**í•„ìˆ˜**: 
- technology_scoreëŠ” category_scoresì˜ í•©ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.""")
            ])

            # LLM í˜¸ì¶œ
            chain = eval_prompt | self.llm

            try:
                response = chain.invoke({
                    "startup_name": startup_name,
                    "web_data": web_data[:2000],
                    "pdf_context": pdf_context[:3000],
                    "existing_scores_constraint": existing_scores_constraint
                })

                content = response.content if hasattr(response, 'content') else str(response)
                
                # JSON íŒŒì‹±
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0]
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0]

                evaluation_dict: TechState = json.loads(content.strip())

                # ì ìˆ˜ í•©ê³„ ê²€ì¦
                category_scores = evaluation_dict.get("category_scores", {})
                calculated_total = (
                    category_scores.get("innovation", 0) +
                    category_scores.get("completeness", 0) +
                    category_scores.get("competitiveness", 0) +
                    category_scores.get("patent", 0) +
                    category_scores.get("scalability", 0)
                )
                
                reported_total = evaluation_dict.get("technology_score", 0)

                if abs(calculated_total - reported_total) > 1:
                    print(f"  âš ï¸ ì ìˆ˜ ë¶ˆì¼ì¹˜ ê°ì§€ (ë³´ê³ : {reported_total}, ê³„ì‚°: {calculated_total}) - ì¬ê³„ì‚°ëœ ê°’ ì‚¬ìš©")
                    evaluation_dict["technology_score"] = calculated_total

                print(f"âœ… í‰ê°€ ì™„ë£Œ: {evaluation_dict['technology_score']}ì ")
                print(f"  ì„¸ë¶€: innovation={category_scores.get('innovation', 0)}, "
                      f"completeness={category_scores.get('completeness', 0)}, "
                      f"competitiveness={category_scores.get('competitiveness', 0)}, "
                      f"patent={category_scores.get('patent', 0)}, "
                      f"scalability={category_scores.get('scalability', 0)}")

            except json.JSONDecodeError as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                evaluation_dict: TechState = {
                    "company_name": startup_name,
                    "category_scores": {
                        "innovation": 15,
                        "completeness": 15,
                        "competitiveness": 10,
                        "patent": 5,
                        "scalability": 5
                    },
                    "technology_score": 50,
                    "technology_analysis_basis": f"í‰ê°€ ì‹¤íŒ¨ (JSON íŒŒì‹± ì˜¤ë¥˜): {str(e)}"
                }
            except Exception as e:
                print(f"âŒ í‰ê°€ ì‹¤íŒ¨: {e}")
                evaluation_dict: TechState = {
                    "company_name": startup_name,
                    "category_scores": {
                        "innovation": 15,
                        "completeness": 15,
                        "competitiveness": 10,
                        "patent": 5,
                        "scalability": 5
                    },
                    "technology_score": 50,
                    "technology_analysis_basis": f"í‰ê°€ ì‹¤íŒ¨: {str(e)}"
                }

            current_evaluations = state.get("tech_evaluations", [])
            current_evaluations.append(evaluation_dict)
            state["tech_evaluations"] = current_evaluations
            state["processing_index"] = current_index + 1

            print(f"ì§„í–‰ ìƒí™©: {state['processing_index']}/{len(state['startup_names'])} ì™„ë£Œ")
            print(f"  ëˆ„ì  í‰ê°€ ê²°ê³¼: {len(state['tech_evaluations'])}ê°œ\n")

            return state

        def check_completion(state: WorkflowState) -> str:
            """ëª¨ë“  ìŠ¤íƒ€íŠ¸ì—… í‰ê°€ ì™„ë£Œ ì—¬ë¶€ í™•ì¸"""
            idx = state.get("processing_index", 0)
            total = len(state.get("startup_names", []))

            if idx < total:
                return "continue"
            else:
                return "end"

        # StateGraph ìƒì„±
        workflow = StateGraph(WorkflowState)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("select_startup", select_next_startup)
        workflow.add_node("crawl_web", crawl_web_data)
        workflow.add_node("retrieve_info", retrieve_tech_info)
        workflow.add_node("evaluate", evaluate_technology)

        # ì—£ì§€ ì„¤ì •
        workflow.set_entry_point("select_startup")
        workflow.add_edge("select_startup", "crawl_web")
        workflow.add_edge("crawl_web", "retrieve_info")
        workflow.add_edge("retrieve_info", "evaluate")

        # ì¡°ê±´ë¶€ ì—£ì§€
        workflow.add_conditional_edges(
            "evaluate",
            check_completion,
            {
                "continue": "select_startup",
                "end": END
            }
        )

        # ê·¸ë˜í”„ ì»´íŒŒì¼
        self.app = workflow.compile()

        print("\nì›Œí¬í”Œë¡œìš° êµ¬ì„± ì™„ë£Œ!")
        print("ìˆœì„œ: select_startup -> crawl_web -> retrieve_info -> evaluate -> [ë°˜ë³µ or ì¢…ë£Œ]\n")

    def get_tech_result(self) -> TechState:
        """
        ê¸°ìˆ  í‰ê°€ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜

        Returns:
            TechState: ê¸°ìˆ  í‰ê°€ ê²°ê³¼
        """
        # VectorStore ì´ˆê¸°í™” (ì•„ì§ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´)
        if self.vectorstore is None:
            self._initialize_vectorstore()

        # Workflow êµ¬ì„± (ì•„ì§ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´)
        if self.app is None:
            self._build_workflow()

        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state: WorkflowState = {
            "startup_names": self.startup_names,
            "current_startup": "",
            "web_data": "",
            "retrieved_docs": [],
            "tech_evaluations": [],
            "processing_index": 0,
            "vectorstore_ready": True
        }

        # ì—ì´ì „íŠ¸ ì‹¤í–‰
        print(f"\n{'='*60}")
        print(f"AI ìŠ¤íƒ€íŠ¸ì—… ê¸°ìˆ  í‰ê°€ ì—ì´ì „íŠ¸ ì‹œì‘")
        print(f"í‰ê°€ ëŒ€ìƒ: {len(self.startup_names)}ê°œ ê¸°ì—…")
        print(f"{'='*60}")

        result = self.app.invoke(initial_state)

        print(f"\n{'='*60}")
        print(f"ì „ì²´ í‰ê°€ ì™„ë£Œ")
        print(f"ìµœì¢… í‰ê°€ ê²°ê³¼ ìˆ˜: {len(result['tech_evaluations'])}ê°œ")
        print(f"{'='*60}\n")
        
        # tech_evaluationsì—ì„œ ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
        tech_evaluations = result.get("tech_evaluations", [])
        
        if not tech_evaluations:
            # í‰ê°€ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "company_name": self.startup_names[0] if self.startup_names else "Unknown",
                "category_scores": {
                    "innovation": 0,
                    "completeness": 0,
                    "competitiveness": 0,
                    "patent": 0,
                    "scalability": 0
                },
                "technology_score": 0,
                "technology_analysis_basis": "í‰ê°€ ì‹¤íŒ¨: ê²°ê³¼ ì—†ìŒ"
            }
        
        return tech_evaluations[0]