from __future__ import annotations

import os
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€ (import ì „ì— ì‹¤í–‰)
ROOT_DIR = os.path.normpath(os.path.join(os.path.dirname(__file__), os.pardir))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

import re
from typing import TypedDict

from dotenv import load_dotenv
from openai import OpenAI

from rag.company_comparison.hybrid_store import HybridStore


# LangGraph State ì •ì˜
class AgentState(TypedDict, total=False):
    """Multi-Agent í†µí•© State"""
    # ê³µí†µ
    startup_name: str
    
    # ê¸°ì—…ë¹„êµ Agent
    competitor_score: int
    competitor_analysis_basis: str


def _extract_score_and_summary(text: str) -> tuple[int, str]:
    """
    GPT ì‘ë‹µì—ì„œ ì ìˆ˜ì™€ ìš”ì•½ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        text: GPT ì‘ë‹µ í…ìŠ¤íŠ¸
        
    Returns:
        (ì ìˆ˜, ìš”ì•½) íŠœí”Œ
    """
    # ì ìˆ˜ íŒ¨í„´: "45ì ", "ì ìˆ˜: 45", "**45ì **", "í‰ê°€: 45" ë“±
    score_patterns = [
        r'(?:ì ìˆ˜[:\s]*)?[\*]*(\d{1,3})[\*]*ì ',  # "45ì ", "**45ì **"
        r'(?:í‰ê°€|ì ìˆ˜)[:\s]+(\d{1,3})',           # "í‰ê°€: 45", "ì ìˆ˜: 45"
        r'\b(100|\d{1,2})\s*ì ',                   # "45 ì "
        r'\b(100|\d{1,2})/100',                    # "45/100"
    ]
    
    score = 50  # ê¸°ë³¸ê°’
    
    for pattern in score_patterns:
        m = re.search(pattern, text)
        if m:
            score = int(m.group(1))
            score = max(0, min(100, score))
            break
    
    # ìš”ì•½ ì¶”ì¶œ: ì „ì²´ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (í‘œ í¬í•¨)
    lines = [ln.strip() for ln in text.strip().splitlines() if ln.strip()]
    
    # ì ìˆ˜ë§Œ ìˆëŠ” ì²« ì¤„ ì œê±°
    if lines and re.match(r'^[\*\s]*\d{1,3}[\*\s]*ì ?[\*\s]*$', lines[0]):
        lines = lines[1:]
    
    # ì „ì²´ ë‚´ìš© ìœ ì§€ (í‘œ + ìš”ì•½)
    return score, "\n".join(lines)


def analyze_competitor(state: AgentState) -> AgentState:
    """
    ê¸°ì—…ë¹„êµ Agent - LangGraph ë…¸ë“œ í•¨ìˆ˜
    
    5ê°œ ê¸°ì—…(íŠ¸ë¦½ì†Œë‹¤, íŠ¸ë¦½ë¹„í† ì¦ˆ, í•˜ì´ì–´í”Œë ˆì´ìŠ¤, ë¦¬ë¸Œì• ë‹ˆì›¨ì–´, ì–´ë”©)ì„
    ì¬ë¬´/íˆ¬ì/ì†Œë¹„ì/MUV ì§€í‘œ ê¸°ë°˜ìœ¼ë¡œ í‘œ í˜•ì‹ìœ¼ë¡œ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        state: LangGraph State (startup_name í¬í•¨)
        
    Returns:
        ì—…ë°ì´íŠ¸ëœ State (competitor_score, competitor_analysis_basis ì¶”ê°€)
    """
    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    
    startup = state.get("startup_name") or "ìƒ˜í”Œê¸°ì—…"
    print(f"\n{'='*70}")
    print(f"ğŸ” [ê¸°ì—…ë¹„êµ Agent] ë¶„ì„ ì‹œì‘: {startup}")
    print(f"{'='*70}")
    
    # ë¹„êµ ëŒ€ìƒ ê¸°ì—… ë¦¬ìŠ¤íŠ¸
    companies = ["íŠ¸ë¦½ì†Œë‹¤", "íŠ¸ë¦½ë¹„í† ì¦ˆ", "í•˜ì´ì–´í”Œë ˆì´ìŠ¤", "ë¦¬ë¸Œì• ë‹ˆì›¨ì–´", "ì–´ë”©"]
    
    # HybridStore ì´ˆê¸°í™”
    agent_dir = os.path.join(os.path.dirname(__file__), os.pardir, "rag", "company_comparison")
    chroma_dir = os.path.join(agent_dir, ".chroma")
    
    if not os.path.exists(chroma_dir):
        print(f"âŒ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € build_index.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”: {chroma_dir}")
        state["competitor_score"] = 0
        state["competitor_analysis_basis"] = "ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return state
    
    print(f"ğŸ“‚ ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...")
    store = HybridStore(chroma_path=chroma_dir, collection="company_comparison")
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ëª¨ë“  ê¸°ì—… + ì£¼ìš” ì§€í‘œ)
    query = f"{' '.join(companies)} ì¬ë¬´ì œí‘œ ë§¤ì¶œ ìì‚° ë¶€ì±„ íˆ¬ììœ ì¹˜ ì†Œë¹„ì ì„±ë³„ ê±°ë˜ MUV"
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    results = store.search(query=query, k_bm25=15, k_vec=15, rrf_k=60, lambda_vec=0.3)
    
    # ìƒìœ„ ê²°ê³¼ í•„í„°ë§ (ë‹¤ì–‘í•œ í˜ì´ì§€ ì„ í˜¸)
    seen_pages = set()
    picked = []
    
    for r in results:
        m = r.get("metadata", {}) or {}
        page = m.get("page")
        
        # í˜ì´ì§€ ì¤‘ë³µ ìµœì†Œí™”í•˜ë˜ ì¶©ë¶„í•œ ë°ì´í„° í™•ë³´
        if page in seen_pages and len(picked) >= 10:
            continue
        
        seen_pages.add(page)
        picked.append(r)
        
        if len(picked) >= 15:
            break
    
    # Context êµ¬ì„±
    context_lines = []
    for r in picked[:15]:
        meta = r.get("metadata", {}) or {}
        page = meta.get("page")
        page_str = f" (p.{page})" if page else ""
        
        txt = (r.get("text") or "").replace("\n", " ").strip()
        # í‘œ ë°ì´í„°ëŠ” ê¸¸ì–´ë„ ìœ ì§€
        if len(txt) > 500:
            txt = txt[:500] + "..."
        
        context_lines.append(f"[{page_str}] {txt}")
    
    context = "\n\n".join(context_lines)
    print(f"ğŸ“‹ ê²€ìƒ‰ëœ ê·¼ê±° ìˆ˜: {len(picked)}")
    
    # GPT í˜¸ì¶œ - êµ¬ì¡°í™”ëœ ë¹„êµ ë¶„ì„
    client = OpenAI()
    
    sys_prompt = """ë‹¹ì‹ ì€ ìŠ¤íƒ€íŠ¸ì—… ê²½ìŸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì •ëŸ‰ì  ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ 5ê°œ ê¸°ì—…ì„ ê°ê´€ì ìœ¼ë¡œ ë¹„êµí•˜ê³ , 
ëª…í™•í•œ ìˆœìœ„ì™€ ê·¼ê±°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

**ì¤‘ìš”:** ë¶„ì„ ëŒ€ìƒ ê¸°ì—…ì—ê²Œ ìœ ë¦¬í•œ í¸í–¥ ì—†ì´ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”."""
    
    user_prompt = f"""# ê¸°ì—… ë¹„êµ ë¶„ì„ ìš”ì²­

**5ê°œ ë¹„êµ ëŒ€ìƒ ê¸°ì—…:** íŠ¸ë¦½ì†Œë‹¤, íŠ¸ë¦½ë¹„í† ì¦ˆ, í•˜ì´ì–´í”Œë ˆì´ìŠ¤, ë¦¬ë¸Œì• ë‹ˆì›¨ì–´, ì–´ë”©
**ì´ ì¤‘ ë¶„ì„ ìš”ì²­ ê¸°ì—…:** {startup}

## ë¶„ì„ ì§€í‘œ
1. **ì¬ë¬´ ê±´ì „ì„±** (ìì‚°, ë¶€ì±„, ìë³¸, ë§¤ì¶œ ì¦ê°€ìœ¨)
2. **íˆ¬ì ìœ ì¹˜** (íˆ¬ì ìœ ì¹˜ ê¸ˆì•¡, íˆ¬ì ë¼ìš´ë“œ)
3. **ì‹œì¥ ì„±ê³¼** (MUV, ê±°ë˜ì•¡, ì†Œë¹„ì ìˆ˜)
4. **ì†Œë¹„ì íŠ¹ì„±** (ì„±ë³„ ë¶„í¬, ì—°ë ¹ëŒ€)

## ì¶œë ¥ í˜•ì‹

### 1ë‹¨ê³„: ì ìˆ˜ (ì²« ì¤„)
- **ë°˜ë“œì‹œ 5ê°œ ê¸°ì—…ì„ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìˆœìœ„ë¥¼ ë§¤ê¸´ í›„** ì ìˆ˜ ì‚°ì •
- 1ìœ„: 100ì , 2ìœ„: 75ì , 3ìœ„: 50ì , 4ìœ„: 25ì , 5ìœ„: 0ì 
- {startup}ê°€ 1ìœ„ê°€ ì•„ë‹ ìˆ˜ ìˆìœ¼ë©°, ì‹¤ì œ ë°ì´í„°ì— ë”°ë¼ ìˆœìœ„ê°€ ê²°ì •ë¨
- ì ìˆ˜ë§Œ ìˆ«ìë¡œ ëª…ì‹œ (ì˜ˆ: "75")

### 2ë‹¨ê³„: ë¹„êµí‘œ (ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”)
**5ê°œ ê¸°ì—… ëª¨ë‘ í¬í•¨í•˜ì—¬ ì‘ì„±**
| ê¸°ì—…ëª… | ì¬ë¬´ê±´ì „ì„± | íˆ¬ììœ ì¹˜ | ì‹œì¥ì„±ê³¼ | ì¢…í•©ìˆœìœ„ |
|--------|-----------|---------|---------|---------|
| íŠ¸ë¦½ì†Œë‹¤ | ... | ... | ... | Xìœ„ |
| íŠ¸ë¦½ë¹„í† ì¦ˆ | ... | ... | ... | Xìœ„ |
| í•˜ì´ì–´í”Œë ˆì´ìŠ¤ | ... | ... | ... | Xìœ„ |
| ë¦¬ë¸Œì• ë‹ˆì›¨ì–´ | ... | ... | ... | Xìœ„ |
| ì–´ë”© | ... | ... | ... | Xìœ„ |

### 3ë‹¨ê³„: ìš”ì•½ (3~5ì¤„)
- **{startup}ì˜ ê°•ì :**
- **{startup}ì˜ ì•½ì :**
- **ê²½ìŸì‚¬ ëŒ€ë¹„ í¬ì§€ì…˜:**
- **ìˆœìœ„ ê·¼ê±°:** (ì™œ ì´ ìˆœìœ„ì¸ì§€ ì •ëŸ‰ ë°ì´í„°ë¡œ ì„¤ëª…)

## ê·¼ê±° ìë£Œ
{context}

**ê²½ê³ :** 
- {startup}ë¥¼ ë¬´ì¡°ê±´ 1ìœ„ë¡œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
- ì‹¤ì œ ë°ì´í„°(ìì‚°, ë§¤ì¶œ, íˆ¬ìì•¡ ë“±)ë¥¼ ë¹„êµí•˜ì—¬ ê°ê´€ì ìœ¼ë¡œ ìˆœìœ„ë¥¼ ë§¤ê¸°ì„¸ìš”.
- ê·¼ê±° ìë£Œì— ìˆëŠ” ì‹¤ì œ ìˆ˜ì¹˜ë¥¼ í™œìš©í•˜ì„¸ìš”.
- í‘œì— 5ê°œ ê¸°ì—…ì„ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”."""
    
    print("ğŸ¤– GPT ë¶„ì„ ì¤‘...")
    
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.2,
        max_tokens=2000,
    )
    
    content = completion.choices[0].message.content or ""
    
    # ì ìˆ˜ ë° ìš”ì•½ íŒŒì‹±
    score, summary = _extract_score_and_summary(content)
    
    # State ì—…ë°ì´íŠ¸
    state["competitor_score"] = int(score)
    state["competitor_analysis_basis"] = summary.strip()
    
    print(f"âœ… ë¶„ì„ ì™„ë£Œ - ì ìˆ˜: {score}ì ")
    
    return state


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
analyze_company_comparison = analyze_competitor


if __name__ == "__main__":
    # ë‹¨ë… í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    from typing import cast
    
    init_state: AgentState = {
        "startup_name": os.environ.get("STARTUP_NAME", "ì–´ë”©")
    }
    
    result = analyze_competitor(init_state)
    
    print("\n" + "="*70)
    print("ğŸ“Š ê¸°ì—…ë¹„êµ ë¶„ì„ ê²°ê³¼")
    print("="*70)
    print(f"\nğŸ¯ ê²½ìŸì‚¬ ì ìˆ˜: {result.get('competitor_score')}ì \n")
    print("ğŸ“‹ ë¶„ì„ ë‚´ìš©:")
    print("-"*70)
    print(result.get("competitor_analysis_basis", "").strip())
    print("="*70)